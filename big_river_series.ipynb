{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0d0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely import contains_xy\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63c0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(lon, lat, shape_gdf):\n",
    "    lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "    points = np.vstack((lon_grid.ravel(), lat_grid.ravel())).T\n",
    "    mask = contains_xy(shape_gdf.union_all(), points[:, 0], points[:, 1])\n",
    "    mask = np.float32(mask)\n",
    "    mask[mask == 0] = np.nan\n",
    "    return mask.reshape(lon_grid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "971db1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_selections = pd.read_csv(\"../data/big_river_selection.txt\", sep=\"\\t\")\n",
    "basin_list = all_selections[\"grdc_no\"].tolist()\n",
    "basins_shape = gpd.read_file(\"../data/shape/stationbasins.shp\")\n",
    "\n",
    "lon_series = np.load(\"../../2025_04_Params_Transplant/Data/forcing/lon.npy\")\n",
    "lat_series = np.load(\"../../2025_04_Params_Transplant/Data/forcing/lat.npy\")\n",
    "\n",
    "time_series_historical = pd.date_range(start=\"1850-01-01\", end=\"2014-12-31\", freq=\"MS\")\n",
    "time_series_future = pd.date_range(start=\"2015-01-01\", end=\"2099-12-31\", freq=\"MS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822ec3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80333623c3f6421a8b6080632e8e8503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing pr:   0%|          | 0/1194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d48f6fb85194298994da8104f1379d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing pet:   0%|          | 0/1194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "element_list = [\"pr\", \"pet\"]\n",
    "for element in element_list:\n",
    "    results_historical = np.full((len(time_series_historical), len(basin_list)), np.nan)\n",
    "    results_126        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_245        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_370        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_585        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "\n",
    "    gcm_historical = np.load(f\"../data/mme/{element}_bc/{element}_historical_bc_mme.npy\").astype(np.float32)\n",
    "    gcm_126        = np.load(f\"../data/mme/{element}_bc/{element}_ssp126_bc_mme.npy\").astype(np.float32)\n",
    "    gcm_245        = np.load(f\"../data/mme/{element}_bc/{element}_ssp245_bc_mme.npy\").astype(np.float32)\n",
    "    gcm_370        = np.load(f\"../data/mme/{element}_bc/{element}_ssp370_bc_mme.npy\").astype(np.float32)\n",
    "    gcm_585        = np.load(f\"../data/mme/{element}_bc/{element}_ssp585_bc_mme.npy\").astype(np.float32)\n",
    "    for b in trange(len(basin_list), desc=f\"Processing {element}\"):\n",
    "        basin = basin_list[b]\n",
    "        # 找 shapefile 子集\n",
    "        basin_shp = basins_shape[basins_shape[\"grdc_no\"] == basin]\n",
    "        polygon = basin_shp.geometry\n",
    "        minx, miny, maxx, maxy = polygon.total_bounds\n",
    "        # 流域上下左右边界\n",
    "        basin_left_bound = minx - 0.2\n",
    "        basin_right_bound = maxx + 0.5\n",
    "        basun_top_bound = maxy + 0.5\n",
    "        basin_bottom_bound = miny - 0.2\n",
    "        # 寻找落在流域边界内的格点\n",
    "        lon_loc = np.where((lon_series >= basin_left_bound) & (lon_series <= basin_right_bound))[0]\n",
    "        lat_loc = np.where((lat_series >= basin_bottom_bound) & (lat_series <= basun_top_bound))[0]\n",
    "        temp_lon = lon_series[lon_loc]\n",
    "        temp_lat = lat_series[lat_loc]\n",
    "        # 计算 mask\n",
    "        basin_mask = get_mask(temp_lon, temp_lat, basin_shp)\n",
    "        # 区域平均\n",
    "        temp_gcm_historical = gcm_historical[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_126        = gcm_126[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_245        = gcm_245[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_370        = gcm_370[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_585        = gcm_585[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        basin_series_historical = np.nanmean(temp_gcm_historical * basin_mask, axis=(1, 2))\n",
    "        basin_series_126        = np.nanmean(temp_gcm_126        * basin_mask, axis=(1, 2))\n",
    "        basin_series_245        = np.nanmean(temp_gcm_245        * basin_mask, axis=(1, 2))\n",
    "        basin_series_370        = np.nanmean(temp_gcm_370        * basin_mask, axis=(1, 2))\n",
    "        basin_series_585        = np.nanmean(temp_gcm_585        * basin_mask, axis=(1, 2))\n",
    "        results_historical[:, b] = basin_series_historical\n",
    "        results_126[:, b]        = basin_series_126\n",
    "        results_245[:, b]        = basin_series_245\n",
    "        results_370[:, b]        = basin_series_370\n",
    "        results_585[:, b]        = basin_series_585\n",
    "    results_historical_df = pd.DataFrame(results_historical, index=time_series_historical, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_historical_df.index.name = \"Time\"\n",
    "    results_historical_df.to_csv(f\"../results/big_river_series/{element}_bc/{element}_historical_bc_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_126_df = pd.DataFrame(results_126, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_126_df.index.name = \"Time\"\n",
    "    results_126_df.to_csv(f\"../results/big_river_series/{element}_bc/{element}_ssp126_bc_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_245_df = pd.DataFrame(results_245, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_245_df.index.name = \"Time\"\n",
    "    results_245_df.to_csv(f\"../results/big_river_series/{element}_bc/{element}_ssp245_bc_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_370_df = pd.DataFrame(results_370, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_370_df.index.name = \"Time\"\n",
    "    results_370_df.to_csv(f\"../results/big_river_series/{element}_bc/{element}_ssp370_bc_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_585_df = pd.DataFrame(results_585, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_585_df.index.name = \"Time\"\n",
    "    results_585_df.to_csv(f\"../results/big_river_series/{element}_bc/{element}_ssp585_bc_series.txt\", sep=\"\\t\", float_format=\"%.1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff7d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"error\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element_list = [\"pr\", \"pet\", \"evspsbl\", \"mrso\"]\n",
    "element_list = [\"mrso\"]\n",
    "for element in element_list:\n",
    "    results_historical = np.full((len(time_series_historical), len(basin_list)), np.nan)\n",
    "    results_126        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_245        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_370        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_585        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "\n",
    "    gcm_historical = np.load(f\"../data/mme/{element}_ds/{element}_historical_ds_mme.npy\").astype(np.float32)\n",
    "    gcm_126        = np.load(f\"../data/mme/{element}_ds/{element}_ssp126_ds_mme.npy\").astype(np.float32)\n",
    "    gcm_245        = np.load(f\"../data/mme/{element}_ds/{element}_ssp245_ds_mme.npy\").astype(np.float32)\n",
    "    gcm_370        = np.load(f\"../data/mme/{element}_ds/{element}_ssp370_ds_mme.npy\").astype(np.float32)\n",
    "    gcm_585        = np.load(f\"../data/mme/{element}_ds/{element}_ssp585_ds_mme.npy\").astype(np.float32)\n",
    "    for b in trange(len(basin_list), desc=f\"Processing {element}\"):\n",
    "        basin = basin_list[b]\n",
    "        # 找 shapefile 子集\n",
    "        basin_shp = basins_shape[basins_shape[\"grdc_no\"] == basin]\n",
    "        polygon = basin_shp.geometry\n",
    "        minx, miny, maxx, maxy = polygon.total_bounds\n",
    "        # 流域上下左右边界\n",
    "        basin_left_bound = minx - 0.2\n",
    "        basin_right_bound = maxx + 0.5\n",
    "        basun_top_bound = maxy + 0.5\n",
    "        basin_bottom_bound = miny - 0.2\n",
    "        # 寻找落在流域边界内的格点\n",
    "        lon_loc = np.where((lon_series >= basin_left_bound) & (lon_series <= basin_right_bound))[0]\n",
    "        lat_loc = np.where((lat_series >= basin_bottom_bound) & (lat_series <= basun_top_bound))[0]\n",
    "        temp_lon = lon_series[lon_loc]\n",
    "        temp_lat = lat_series[lat_loc]\n",
    "        # 计算 mask\n",
    "        basin_mask = get_mask(temp_lon, temp_lat, basin_shp)\n",
    "        # 区域平均\n",
    "        temp_gcm_historical = gcm_historical[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_126        = gcm_126[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_245        = gcm_245[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_370        = gcm_370[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_585        = gcm_585[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        basin_series_historical = np.nanmean(temp_gcm_historical * basin_mask, axis=(1, 2))\n",
    "        basin_series_126        = np.nanmean(temp_gcm_126        * basin_mask, axis=(1, 2))\n",
    "        basin_series_245        = np.nanmean(temp_gcm_245        * basin_mask, axis=(1, 2))\n",
    "        basin_series_370        = np.nanmean(temp_gcm_370        * basin_mask, axis=(1, 2))\n",
    "        basin_series_585        = np.nanmean(temp_gcm_585        * basin_mask, axis=(1, 2))\n",
    "        results_historical[:, b] = basin_series_historical\n",
    "        results_126[:, b]        = basin_series_126\n",
    "        results_245[:, b]        = basin_series_245\n",
    "        results_370[:, b]        = basin_series_370\n",
    "        results_585[:, b]        = basin_series_585\n",
    "    results_historical_df = pd.DataFrame(results_historical, index=time_series_historical, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_historical_df.index.name = \"Time\"\n",
    "    results_historical_df.to_csv(f\"../results/big_river_series/{element}_ds/{element}_historical_ds_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_126_df = pd.DataFrame(results_126, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_126_df.index.name = \"Time\"\n",
    "    results_126_df.to_csv(f\"../results/big_river_series/{element}_ds/{element}_ssp126_ds_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_245_df = pd.DataFrame(results_245, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_245_df.index.name = \"Time\"\n",
    "    results_245_df.to_csv(f\"../results/big_river_series/{element}_ds/{element}_ssp245_ds_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_370_df = pd.DataFrame(results_370, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_370_df.index.name = \"Time\"\n",
    "    results_370_df.to_csv(f\"../results/big_river_series/{element}_ds/{element}_ssp370_ds_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_585_df = pd.DataFrame(results_585, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_585_df.index.name = \"Time\"\n",
    "    results_585_df.to_csv(f\"../results/big_river_series/{element}_ds/{element}_ssp585_ds_series.txt\", sep=\"\\t\", float_format=\"%.1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b01105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b3041087804b8baaad950c0dec338e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing natural_runoff:   0%|          | 0/1194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3edd1d2db042b88cff78d69e73f258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing actural_evaporation:   0%|          | 0/1194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187eebb7804f4975b2013b6e6430c4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing soil_moisture:   0%|          | 0/1194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "element_list = [\"natural_runoff\", \"actural_evaporation\", \"soil_moisture\"]\n",
    "for element in element_list:\n",
    "    results_historical = np.full((len(time_series_historical), len(basin_list)), np.nan)\n",
    "    results_126        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_245        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_370        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "    results_585        = np.full((len(time_series_future), len(basin_list)), np.nan)\n",
    "\n",
    "    gcm_historical = np.load(f\"../data/mme/{element}/{element}_historical_mme.npy\").astype(np.float32)\n",
    "    gcm_126        = np.load(f\"../data/mme/{element}/{element}_ssp126_mme.npy\").astype(np.float32)\n",
    "    gcm_245        = np.load(f\"../data/mme/{element}/{element}_ssp245_mme.npy\").astype(np.float32)\n",
    "    gcm_370        = np.load(f\"../data/mme/{element}/{element}_ssp370_mme.npy\").astype(np.float32)\n",
    "    gcm_585        = np.load(f\"../data/mme/{element}/{element}_ssp585_mme.npy\").astype(np.float32)\n",
    "    gcm_historical[0] = gcm_historical[1]\n",
    "    gcm_126[0]        = gcm_126[1]\n",
    "    gcm_245[0]        = gcm_245[1]\n",
    "    gcm_370[0]        = gcm_370[1]\n",
    "    gcm_585[0]        = gcm_585[1]\n",
    "    for b in trange(len(basin_list), desc=f\"Processing {element}\"):\n",
    "        basin = basin_list[b]\n",
    "        # 找 shapefile 子集\n",
    "        basin_shp = basins_shape[basins_shape[\"grdc_no\"] == basin]\n",
    "        polygon = basin_shp.geometry\n",
    "        minx, miny, maxx, maxy = polygon.total_bounds\n",
    "        # 流域上下左右边界\n",
    "        basin_left_bound = minx - 0.2\n",
    "        basin_right_bound = maxx + 0.5\n",
    "        basun_top_bound = maxy + 0.5\n",
    "        basin_bottom_bound = miny - 0.2\n",
    "        # 寻找落在流域边界内的格点\n",
    "        lon_loc = np.where((lon_series >= basin_left_bound) & (lon_series <= basin_right_bound))[0]\n",
    "        lat_loc = np.where((lat_series >= basin_bottom_bound) & (lat_series <= basun_top_bound))[0]\n",
    "        temp_lon = lon_series[lon_loc]\n",
    "        temp_lat = lat_series[lat_loc]\n",
    "        # 计算 mask\n",
    "        basin_mask = get_mask(temp_lon, temp_lat, basin_shp)\n",
    "        # 区域平均\n",
    "        temp_gcm_historical = gcm_historical[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_126        = gcm_126[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_245        = gcm_245[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_370        = gcm_370[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        temp_gcm_585        = gcm_585[:, lat_loc[0]:lat_loc[-1]+1, lon_loc[0]:lon_loc[-1]+1]\n",
    "        basin_series_historical = np.nanmean(temp_gcm_historical * basin_mask, axis=(1, 2))\n",
    "        basin_series_126        = np.nanmean(temp_gcm_126        * basin_mask, axis=(1, 2))\n",
    "        basin_series_245        = np.nanmean(temp_gcm_245        * basin_mask, axis=(1, 2))\n",
    "        basin_series_370        = np.nanmean(temp_gcm_370        * basin_mask, axis=(1, 2))\n",
    "        basin_series_585        = np.nanmean(temp_gcm_585        * basin_mask, axis=(1, 2))\n",
    "        results_historical[:, b] = basin_series_historical\n",
    "        results_126[:, b]        = basin_series_126\n",
    "        results_245[:, b]        = basin_series_245\n",
    "        results_370[:, b]        = basin_series_370\n",
    "        results_585[:, b]        = basin_series_585\n",
    "    results_historical_df = pd.DataFrame(results_historical, index=time_series_historical, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_historical_df.index.name = \"Time\"\n",
    "    results_historical_df.to_csv(f\"../results/big_river_series/{element}/{element}_historical_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_126_df = pd.DataFrame(results_126, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_126_df.index.name = \"Time\"\n",
    "    results_126_df.to_csv(f\"../results/big_river_series/{element}/{element}_ssp126_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_245_df = pd.DataFrame(results_245, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_245_df.index.name = \"Time\"\n",
    "    results_245_df.to_csv(f\"../results/big_river_series/{element}/{element}_ssp245_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_370_df = pd.DataFrame(results_370, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_370_df.index.name = \"Time\"\n",
    "    results_370_df.to_csv(f\"../results/big_river_series/{element}/{element}_ssp370_series.txt\", sep=\"\\t\", float_format=\"%.1f\")\n",
    "\n",
    "    results_585_df = pd.DataFrame(results_585, index=time_series_future, columns=basin_list).resample(\"YS\").sum(min_count=1)\n",
    "    results_585_df.index.name = \"Time\"\n",
    "    results_585_df.to_csv(f\"../results/big_river_series/{element}/{element}_ssp585_series.txt\", sep=\"\\t\", float_format=\"%.1f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
